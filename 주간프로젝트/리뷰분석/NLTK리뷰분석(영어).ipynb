{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.__version__ #'3.8.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this\n",
    "\n",
    "\n",
    "text_sample = \"\"\"Beautiful is better than ugly.\n",
    "Explicit is better than implicit.\n",
    "Simple is better than complex.\n",
    "Complex is better than complicated.\n",
    "Flat is better than nested.\n",
    "Sparse is better than dense.\n",
    "Readability counts.\n",
    "Special cases aren't special enough to break the rules.\n",
    "Although practicality beats purity.\n",
    "Errors should never pass silently.\n",
    "Unless explicitly silenced.\n",
    "In the face of ambiguity, refuse the temptation to guess.\n",
    "There should be one-- and preferably only one --obvious way to do it.\n",
    "Although that way may not be obvious at first unless you're Dutch.\n",
    "Now is better than never.\n",
    "Although never is often better than *right* now.\n",
    "If the implementation is hard to explain, it's a bad idea.\n",
    "If the implementation is easy to explain, it may be a good idea.\n",
    "Namespaces are one honking great idea -- let's do more of those!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Master\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Beautiful is better than ugly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Beautiful is better than ugly.',\n",
       " 'Explicit is better than implicit.',\n",
       " 'Simple is better than complex.',\n",
       " 'Complex is better than complicated.',\n",
       " 'Flat is better than nested.',\n",
       " 'Sparse is better than dense.',\n",
       " 'Readability counts.',\n",
       " \"Special cases aren't special enough to break the rules.\",\n",
       " 'Although practicality beats purity.',\n",
       " 'Errors should never pass silently.',\n",
       " 'Unless explicitly silenced.',\n",
       " 'In the face of ambiguity, refuse the temptation to guess.',\n",
       " 'There should be one-- and preferably only one --obvious way to do it.',\n",
       " \"Although that way may not be obvious at first unless you're Dutch.\",\n",
       " 'Now is better than never.',\n",
       " 'Although never is often better than *right* now.',\n",
       " \"If the implementation is hard to explain, it's a bad idea.\",\n",
       " 'If the implementation is easy to explain, it may be a good idea.',\n",
       " \"Namespaces are one honking great idea -- let's do more of those!\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sent_tokenize() : 문장단위로 나눠준다.\n",
    "# word_tokenize() : 단어단위로 나눠준다.\n",
    "# regexp_tokenize() : 토큰의 단위를 정규표현식으로 지정\n",
    "# 반환타입 : 토큰하나 하나를 원소로 하는 list\n",
    "\n",
    "\n",
    "sentences = nltk.sent_tokenize(text_sample) # 구분자 :\".\"\n",
    "print(len(sentences))\n",
    "print(sentences[0])\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Beautiful',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'ugly',\n",
       " '.',\n",
       " 'Explicit',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'implicit',\n",
       " '.',\n",
       " 'Simple',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'complex',\n",
       " '.',\n",
       " 'Complex',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'complicated',\n",
       " '.',\n",
       " 'Flat',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'nested',\n",
       " '.',\n",
       " 'Sparse',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'dense',\n",
       " '.',\n",
       " 'Readability',\n",
       " 'counts',\n",
       " '.',\n",
       " 'Special',\n",
       " 'cases',\n",
       " 'are',\n",
       " \"n't\",\n",
       " 'special',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'break',\n",
       " 'the',\n",
       " 'rules',\n",
       " '.',\n",
       " 'Although',\n",
       " 'practicality',\n",
       " 'beats',\n",
       " 'purity',\n",
       " '.',\n",
       " 'Errors',\n",
       " 'should',\n",
       " 'never',\n",
       " 'pass',\n",
       " 'silently',\n",
       " '.',\n",
       " 'Unless',\n",
       " 'explicitly',\n",
       " 'silenced',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'face',\n",
       " 'of',\n",
       " 'ambiguity',\n",
       " ',',\n",
       " 'refuse',\n",
       " 'the',\n",
       " 'temptation',\n",
       " 'to',\n",
       " 'guess',\n",
       " '.',\n",
       " 'There',\n",
       " 'should',\n",
       " 'be',\n",
       " 'one',\n",
       " '--',\n",
       " 'and',\n",
       " 'preferably',\n",
       " 'only',\n",
       " 'one',\n",
       " '--',\n",
       " 'obvious',\n",
       " 'way',\n",
       " 'to',\n",
       " 'do',\n",
       " 'it',\n",
       " '.',\n",
       " 'Although',\n",
       " 'that',\n",
       " 'way',\n",
       " 'may',\n",
       " 'not',\n",
       " 'be',\n",
       " 'obvious',\n",
       " 'at',\n",
       " 'first',\n",
       " 'unless',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'Dutch',\n",
       " '.',\n",
       " 'Now',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'never',\n",
       " '.',\n",
       " 'Although',\n",
       " 'never',\n",
       " 'is',\n",
       " 'often',\n",
       " 'better',\n",
       " 'than',\n",
       " '*',\n",
       " 'right',\n",
       " '*',\n",
       " 'now',\n",
       " '.',\n",
       " 'If',\n",
       " 'the',\n",
       " 'implementation',\n",
       " 'is',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'explain',\n",
       " ',',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'bad',\n",
       " 'idea',\n",
       " '.',\n",
       " 'If',\n",
       " 'the',\n",
       " 'implementation',\n",
       " 'is',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'explain',\n",
       " ',',\n",
       " 'it',\n",
       " 'may',\n",
       " 'be',\n",
       " 'a',\n",
       " 'good',\n",
       " 'idea',\n",
       " '.',\n",
       " 'Namespaces',\n",
       " 'are',\n",
       " 'one',\n",
       " 'honking',\n",
       " 'great',\n",
       " 'idea',\n",
       " '--',\n",
       " 'let',\n",
       " \"'s\",\n",
       " 'do',\n",
       " 'more',\n",
       " 'of',\n",
       " 'those',\n",
       " '!']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(text_sample) # 구분자: 공백, 구두점도 하나의 토큰 분리.\n",
    "print(len(words))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Beautiful',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'ugly',\n",
       " 'Explicit',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'implicit',\n",
       " 'Simple',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'complex',\n",
       " 'Complex',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'complicated',\n",
       " 'Flat',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'nested',\n",
       " 'Sparse',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'dense',\n",
       " 'Readability',\n",
       " 'counts',\n",
       " 'Special',\n",
       " 'cases',\n",
       " 'aren',\n",
       " 't',\n",
       " 'special',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'break',\n",
       " 'the',\n",
       " 'rules',\n",
       " 'Although',\n",
       " 'practicality',\n",
       " 'beats',\n",
       " 'purity',\n",
       " 'Errors',\n",
       " 'should',\n",
       " 'never',\n",
       " 'pass',\n",
       " 'silently',\n",
       " 'Unless',\n",
       " 'explicitly',\n",
       " 'silenced',\n",
       " 'In',\n",
       " 'the',\n",
       " 'face',\n",
       " 'of',\n",
       " 'ambiguity',\n",
       " 'refuse',\n",
       " 'the',\n",
       " 'temptation',\n",
       " 'to',\n",
       " 'guess',\n",
       " 'There',\n",
       " 'should',\n",
       " 'be',\n",
       " 'one',\n",
       " 'and',\n",
       " 'preferably',\n",
       " 'only',\n",
       " 'one',\n",
       " 'obvious',\n",
       " 'way',\n",
       " 'to',\n",
       " 'do',\n",
       " 'it',\n",
       " 'Although',\n",
       " 'that',\n",
       " 'way',\n",
       " 'may',\n",
       " 'not',\n",
       " 'be',\n",
       " 'obvious',\n",
       " 'at',\n",
       " 'first',\n",
       " 'unless',\n",
       " 'you',\n",
       " 're',\n",
       " 'Dutch',\n",
       " 'Now',\n",
       " 'is',\n",
       " 'better',\n",
       " 'than',\n",
       " 'never',\n",
       " 'Although',\n",
       " 'never',\n",
       " 'is',\n",
       " 'often',\n",
       " 'better',\n",
       " 'than',\n",
       " 'right',\n",
       " 'now',\n",
       " 'If',\n",
       " 'the',\n",
       " 'implementation',\n",
       " 'is',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'explain',\n",
       " 'it',\n",
       " 's',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'idea',\n",
       " 'If',\n",
       " 'the',\n",
       " 'implementation',\n",
       " 'is',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'explain',\n",
       " 'it',\n",
       " 'may',\n",
       " 'be',\n",
       " 'a',\n",
       " 'good',\n",
       " 'idea',\n",
       " 'Namespaces',\n",
       " 'are',\n",
       " 'one',\n",
       " 'honking',\n",
       " 'great',\n",
       " 'idea',\n",
       " 'let',\n",
       " 's',\n",
       " 'do',\n",
       " 'more',\n",
       " 'of',\n",
       " 'those']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_tokens = nltk.regexp_tokenize(text_sample, '\\w+') #토큰의 패턴을 정규표현식으로 지정.  \\w 글자,숫자,공백\n",
    "print(len(reg_tokens))\n",
    "reg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Master\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'basque',\n",
       " 'bengali',\n",
       " 'catalan',\n",
       " 'chinese',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hebrew',\n",
       " 'hinglish',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#불용어 stopword\n",
    "#문장내에서는 많이 사용되지만 문장의 전체 맥락(내용/뜻)과는 상관없는 단어들.\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, list)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영어 불용어\n",
    "eng_stopwords = stopwords.words('english')\n",
    "len(eng_stopwords), type(eng_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def tokenize_text(text):\n",
    "    # 받은 문장을 소문자로 변환\n",
    "    text = text.lower() #string.lower() 소문자로 변환. string.upper() 대문자로 변환\n",
    "\n",
    "    # 문장단위로 토큰화\n",
    "    sentence_tokens = nltk.sent_tokenize(text)\n",
    "\n",
    "    # 불용어 객체 생성\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend(['although','unless', 'may']) #불용어 객체 추가\n",
    "\n",
    "    # 반복문을 이용해 문장별로 word 단위 토큰화 실행\n",
    "    word_token_list = [] # 최종 결과를 저장할 리스트\n",
    "    for sentence in sentence_tokens:\n",
    "        word_token_gen = nltk.regexp_tokenize(sentence, '[A-Za-z]+')  # \\w: 일반문자, 숫자, 공백\n",
    "        #불용어 제거\n",
    "        word_token = [word for word in word_token_gen if word not in stop_words]\n",
    "\n",
    "        word_token_list.append(word_token)\n",
    "\n",
    "    return word_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['beautiful', 'better', 'ugly'],\n",
       " ['explicit', 'better', 'implicit'],\n",
       " ['simple', 'better', 'complex'],\n",
       " ['complex', 'better', 'complicated'],\n",
       " ['flat', 'better', 'nested'],\n",
       " ['sparse', 'better', 'dense'],\n",
       " ['readability', 'counts'],\n",
       " ['special', 'cases', 'special', 'enough', 'break', 'rules'],\n",
       " ['practicality', 'beats', 'purity'],\n",
       " ['errors', 'never', 'pass', 'silently'],\n",
       " ['explicitly', 'silenced'],\n",
       " ['face', 'ambiguity', 'refuse', 'temptation', 'guess'],\n",
       " ['one', 'preferably', 'one', 'obvious', 'way'],\n",
       " ['way', 'obvious', 'first', 'dutch'],\n",
       " ['better', 'never'],\n",
       " ['never', 'often', 'better', 'right'],\n",
       " ['implementation', 'hard', 'explain', 'bad', 'idea'],\n",
       " ['implementation', 'easy', 'explain', 'good', 'idea'],\n",
       " ['namespaces', 'one', 'honking', 'great', 'idea', 'let']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize_text(text_sample)\n",
    "tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
